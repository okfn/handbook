---
title: Welcome to the Core Datasets guides!
---

If you wish to contribute to the Core Datasets project, this is the place to start. Reading through the [data guides](data-guides/) is also key, specially if you have never worked with data before. These tutorials, courses and instructions will get you to a really independent level, enough to start collaborating to some data packages.

## What is Core Datasets? Why is it any different than the rest?

[OKFN Labs](http://okfnlabs.org/) is the base project that is supporting many other initiatives. The idea there is to build the needed tools so that others can create data packages and make then available. Afterall, that is [OKFN's mission and ultimate goal](https://okfn.org/about/)


One of the main projects is the [Core Datasets](http://data.okfn.org/roadmap/core-datasets). The idea is to ensure we have **core** datasets available for everyone. This means then, we apply [open standards](http://opendefinition.org/) and thus we ensure everyone, or at least their computer, can read that dataset.

In this project, we are creating standardized datasets, in a bulk as CSV with JSON. All this data is grouped in a package and the maintainer must make his data package available - for instance, in [GitHub](https://github.com). This ensure anyone can participate and update each others packages if needed.

*This project is community-based*, as well as many other initiaves, thus we need your help. And, as we will discuss further on, it is part of the [Frictioneless Data Project](http://data.okfn.org/). 


### Why do we need data packages?

Even though many organizations, public and private, like to say they agree with open principles, the truth and reality is a bit different. In addition, if you need data from any project of yours, you will realize that each organization publishes data in a non-standardized matter, and this makes it a very painful experience. 

Core Datasets strikes back by providing datasets in the same format for all of them, following the same rules and standards. This reduces the trouble of finding and getting data, easing the entire experience. Core Datasets also empowers **all** individuals since we struggle to ensure every kind of software will read these data packages - thus we say these packages must be, at least, *machine readable*. This means, whether you use Excel, Python, R or whatever software you prefer, we guarantee you will be able to read your data source painlessly. 

**Reminder:** We do not create data - It is a matter of curation and not creation. We all know many data sources, but as you will see later in the guides, one of the tasks is actually to find the **most reliable** source.

### Solution

If you want to collaborate to Core Datasets, you will be creating core datasets. That means you will:

* Create clean, raw datasets, easy to import (since we propose the usage of CSV and JSON formats);
* You will be creating reliable and up-to-date datasets
* You are opening knowledge
* You are applying a standard structure of information

Guides
------

The following list represents key aspects you have to comprehend before participating in this project. You can take these at your own pace.

If you have never worked with data before and you are apprehensive about your skill set, please dig in to the [Data Guides](data-guides/)

* [Introduction](intro)
* [Key Principles](key-principles)
* [Who can contribute](who-can-contribute)
* [Get Started](getting-started)
* [Core Datasets Curators](core-data-curators)
* [Working with GitHub](working-with-git)
* [Core Datasets Roadmap](core-datasets-roadmap)
* [Your first package](first-package)
